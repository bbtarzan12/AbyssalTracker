import os
import glob
import re
import requests
import pandas as pd
from rich.console import Console
from rich.table import Table
import time
import json

class EVEApi:
    REGION_ID = 10000002  # The Forge
    STATION_ID = 60003760 # Jita 4-4
    CACHE_FILE = os.path.join(os.path.dirname(__file__), 'typeid_cache.json')

    def __init__(self):
        self.name_to_id_cache = self._load_cache()

    def _load_cache(self):
        try:
            with open(self.CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}

    def _save_cache(self):
        with open(self.CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.name_to_id_cache, f, ensure_ascii=False, indent=2)

    def fetch_type_ids(self, names):
        name_to_id = {}
        names_to_query = [n for n in names if n not in self.name_to_id_cache]

        for i in range(0, len(names_to_query), 20):
            chunk = names_to_query[i:i+20]
            try:
                resp = requests.post(
                    "https://esi.evetech.net/latest/universe/ids/",
                    json=chunk,
                    timeout=10,
                    headers={"User-Agent": "bulk-lookup 1.0", "Content-Type": "application/json"}
                )
                resp.raise_for_status()
                data = resp.json()
                for itm in data.get("inventory_types", []):
                    self.name_to_id_cache[itm["name"]] = itm["id"]
                time.sleep(0.2)
            except requests.exceptions.RequestException as e:
                print(f"[ERROR] ESI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        self._save_cache()
        for n in names:
            if n in self.name_to_id_cache:
                name_to_id[n] = self.name_to_id_cache[n]
        return name_to_id

    def fetch_fuzzwork_prices(self, ids):
        url = (f"https://market.fuzzwork.co.uk/aggregates/?region={self.REGION_ID}"
               f"&types={','.join(map(str, ids))}")
        try:
            return requests.get(url, timeout=15).json()
        except requests.exceptions.RequestException as e:
            print(f"[ERROR] Fuzzwork API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}

class AbyssalDataManager:
    def __init__(self, data_dir='data'):
        self.data_dir = data_dir

    def parse_items(self, item_str):
        items = []
        for entry in str(item_str).split(';'):
            entry = entry.strip()
            if not entry:
                continue
            m = re.match(r'(.+?)\*\s*(\d+)?$', entry)
            if m:
                name = m.group(1).strip()
                try:
                    qty = int(m.group(2)) if m.group(2) else 1
                except Exception:
                    qty = 1
                items.append((name, qty))
            else:
                items.append((entry, 1))
        return items

    def abyssal_type_to_filament_name(self, abyssal_type):
        tier_map = {
            'T1': 'Calm', 'T2': 'Agitated', 'T3': 'Fierce',
            'T4': 'Raging', 'T5': 'Chaotic', 'T6': 'Cataclysmic',
        }
        try:
            tier, weather = abyssal_type.split()
            return f'{tier_map[tier]} {weather} Filament'
        except Exception:
            return None

    def load_abyssal_results(self):
        result_files = sorted(glob.glob(os.path.join(self.data_dir, 'abyssal_results_*.csv')))
        if not result_files:
            return pd.DataFrame()

        dfs = []
        for file in result_files:
            df = pd.read_csv(file, encoding='utf-8')
            dfs.append(df)
        return pd.concat(dfs, ignore_index=True)

    def save_abyssal_result(self, result, start_time, end_time):
        items = result.get("items", "").strip()
        if not items:
            return  # ì•„ì´í…œì´ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë¡í•˜ì§€ ì•ŠìŒ

        os.makedirs(self.data_dir, exist_ok=True)
        date_str = start_time.strftime('%Y-%m-%d')
        filename = os.path.join(self.data_dir, f"abyssal_results_{date_str}.csv")
        file_exists = os.path.exists(filename)
        duration_sec = int((end_time - start_time).total_seconds())
        duration_min = round(duration_sec / 60, 2)
        items = items.replace('\n', '; ').replace('\r', '')
        row = {
            "ì‹œì‘ì‹œê°(KST)": start_time.strftime('%Y-%m-%d %H:%M:%S'),
            "ì¢…ë£Œì‹œê°(KST)": end_time.strftime('%Y-%m-%d %H:%M:%S'),
            "ëŸ° ì†Œìš”(ì´ˆ)": duration_sec,
            "ëŸ° ì†Œìš”(ë¶„)": duration_min,
            "ì–´ë¹„ì…œ ì¢…ë¥˜": result.get("abyssal_type", ""),
            "íšë“ ì•„ì´í…œ": items
        }
        df = pd.DataFrame([row])
        df.to_csv(
            filename,
            mode='a',
            header=not file_exists,
            index=False,
            encoding='utf-8-sig'
        )

class AbyssalPriceAnalyzer:
    def __init__(self, eve_api: EVEApi, data_manager: AbyssalDataManager, console: Console):
        self.eve_api = eve_api
        self.data_manager = data_manager
        self.console = console
        self.item_buy_price_cache = {}
        self.item_sell_price_cache = {}
        self.df = pd.DataFrame()

    def get_analysis_data(self):
        # 1. CSV íŒŒì¼ ì½ê¸°
        self.df = self.data_manager.load_abyssal_results()
        if self.df.empty:
            return None # ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜

        # 2. ëª¨ë“  ì•„ì´í…œ ì´ë¦„ ìˆ˜ì§‘
        all_item_names = set()
        for items in self.df['íšë“ ì•„ì´í…œ']:
            for name, qty in self.data_manager.parse_items(items):
                all_item_names.add(name)
        for abyssal_type in self.df['ì–´ë¹„ì…œ ì¢…ë¥˜']:
            filament = self.data_manager.abyssal_type_to_filament_name(abyssal_type)
            if filament:
                all_item_names.add(filament)
        all_item_names = list(all_item_names)

        # 3. ESI APIë¡œ ì•„ì´í…œ type_id ë³€í™˜
        name_to_id = self.eve_api.fetch_type_ids(all_item_names)

        # 4. Fuzzworkë¡œ ëŒ€ëŸ‰ ì‹œì„¸ ì¡°íšŒ
        ids = list(name_to_id.values())
        prices = {}
        for i in range(0, len(ids), 100):
            chunk = ids[i:i+100]
            prices.update(self.eve_api.fetch_fuzzwork_prices(chunk))
            time.sleep(0.2)

        for name, type_id in name_to_id.items():
            p = prices.get(str(type_id))
            if p:
                try:
                    self.item_buy_price_cache[name] = float(p['buy']['max'])
                except Exception:
                    self.item_buy_price_cache[name] = 0.0
                try:
                    self.item_sell_price_cache[name] = float(p['sell']['min'])
                except Exception:
                    self.item_sell_price_cache[name] = 0.0
            else:
                self.item_buy_price_cache[name] = 0.0
                self.item_sell_price_cache[name] = 0.0
        
        self._calculate_run_metrics()

        # í†µê³„ ë°ì´í„° ë°˜í™˜
        daily_stats = {}
        for date, group in self.df.groupby('ë‚ ì§œ'):
            daily_stats[date] = {
                "runs": group.to_dict(orient='records'),
                "avg_isk": group['ì‹¤ìˆ˜ìµ'].mean(),
                "avg_time": group['ëŸ° ì†Œìš”(ë¶„)'].mean(),
                "avg_iskph": group['ISK/h'].mean()
            }
        
        overall_stats = {}
        if not self.df.empty:
            overall_stats = {
                "avg_isk": self.df['ì‹¤ìˆ˜ìµ'].mean(),
                "avg_time": self.df['ëŸ° ì†Œìš”(ë¶„)'].mean(),
                "avg_iskph": self.df['ISK/h'].mean(),
                "tier_weather_stats": []
            }
            for (tier, weather), group in self.df.groupby(self.df['ì–´ë¹„ì…œ ì¢…ë¥˜'].str.split().str[0:2].apply(tuple)):
                if not group.empty:
                    overall_stats["tier_weather_stats"].append({
                        "tier": tier,
                        "weather": weather,
                        "runs_count": len(group),
                        "avg_isk": group['ì‹¤ìˆ˜ìµ'].mean(),
                        "avg_time": group['ëŸ° ì†Œìš”(ë¶„)'].mean(),
                        "avg_iskph": group['ISK/h'].mean()
                    })
        
        return {
            "daily_stats": daily_stats,
            "overall_stats": overall_stats
        }

    def analyze(self):
        self.console.print("\nğŸ“‚ [1/5] CSV íŒŒì¼ ì½ê¸°...", style="bold")
        stats_data = self.get_analysis_data()
        if stats_data is None:
            self.console.print("[red]âŒ ë¶„ì„í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.[/red]")
            return
        
        self.console.print(f"  â–¶ï¸ {len(glob.glob(os.path.join(self.data_manager.data_dir, 'abyssal_results_*.csv')))}ê°œ íŒŒì¼ì—ì„œ ëŸ° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        all_item_names = set()
        for items in self.df['íšë“ ì•„ì´í…œ']:
            for name, qty in self.data_manager.parse_items(items):
                all_item_names.add(name)
        for abyssal_type in self.df['ì–´ë¹„ì…œ ì¢…ë¥˜']:
            filament = self.data_manager.abyssal_type_to_filament_name(abyssal_type)
            if filament:
                all_item_names.add(filament)
        all_item_names = list(all_item_names)
        self.console.print(f"  â–¶ï¸ {len(all_item_names)}ì¢… ì•„ì´í…œ ë°œê²¬!")

        self.console.print("\nğŸ” [2/5] ESI APIë¡œ ì•„ì´í…œ type_id ë³€í™˜ ì¤‘...")
        name_to_id = self.eve_api.fetch_type_ids(all_item_names)
        self.console.print(f"  â–¶ï¸ {len(name_to_id)}ì¢… ë³€í™˜ ì„±ê³µ! (ë¯¸ë§¤ì¹­: {len(all_item_names)-len(name_to_id)})")

        self.console.print("\nğŸ’° [3/5] Fuzzworkë¡œ ëŒ€ëŸ‰ ì‹œì„¸ ì¡°íšŒ ì¤‘...")
        ids = list(name_to_id.values())
        prices = {}
        for i in range(0, len(ids), 100):
            chunk = ids[i:i+100]
            prices.update(self.eve_api.fetch_fuzzwork_prices(chunk))
            time.sleep(0.2)

        self._print_statistics()

    def _calculate_run_metrics(self):
        def calc_run(row):
            items = self.data_manager.parse_items(row['íšë“ ì•„ì´í…œ'])
            total = sum(float(self.item_buy_price_cache.get(name, 0)) * int(qty) for name, qty in items)
            filament = self.data_manager.abyssal_type_to_filament_name(row['ì–´ë¹„ì…œ ì¢…ë¥˜'])
            filament_price = float(self.item_sell_price_cache.get(filament, 0)) * 3  # í”„ë¦¬ê¹ƒ 3ë°°
            duration_min = float(row['ëŸ° ì†Œìš”(ë¶„)'])
            net_isk = total - filament_price
            isk_per_hour = net_isk / (duration_min / 60) if duration_min > 0 else 0
            return pd.Series({
                'ë“œë¡­': total,
                'ì…ì¥ë£Œ': filament_price,
                'ì‹¤ìˆ˜ìµ': net_isk,
                'ISK/h': isk_per_hour
            })

        self.df[['ë“œë¡­', 'ì…ì¥ë£Œ', 'ì‹¤ìˆ˜ìµ', 'ISK/h']] = self.df.apply(calc_run, axis=1)
        self.df['ë‚ ì§œ'] = self.df['ì‹œì‘ì‹œê°(KST)'].str[:10]

    def _print_statistics(self):
        self.console.print("\n==============================", style="bold")
        self.console.print("ğŸ—“ï¸  ë‚ ì§œë³„ ì–´ë¹„ì…œ ëŸ° í†µê³„ ğŸ—“ï¸", style="bold")
        self.console.print("==============================", style="bold")
        for date, group in self.df.groupby('ë‚ ì§œ'):
            table = Table(title=f"ğŸ“… {date}")
            table.add_column("ì‹œì‘ì‹œê°")
            table.add_column("ì–´ë¹„ì…œ ì¢…ë¥˜")
            table.add_column("ëŸ° ì‹œê°„")
            table.add_column("ğŸ’° ë“œë¡­", justify="right")
            table.add_column("ğŸ« ì…ì¥ë£Œ", justify="right")
            table.add_column("ğŸŸ¢ ì‹¤ìˆ˜ìµ", justify="right")
            table.add_column("ğŸ•’ ISK/h", justify="right")
            for _, row in group.iterrows():
                table.add_row(
                    row['ì‹œì‘ì‹œê°(KST)'],
                    row['ì–´ë¹„ì…œ ì¢…ë¥˜'],
                    f"{row['ëŸ° ì†Œìš”(ë¶„)']:.2f}m",
                    f"{int(row['ë“œë¡­']):,}",
                    f"-{int(row['ì…ì¥ë£Œ']):,}",
                    f"{int(row['ì‹¤ìˆ˜ìµ']):,}",
                    f"{int(row['ISK/h']):,}"
                )
            avg_isk = group['ì‹¤ìˆ˜ìµ'].mean()
            avg_time = group['ëŸ° ì†Œìš”(ë¶„)'].mean()
            avg_iskph = group['ISK/h'].mean()
            table.add_row("[í‰ê· ]", "", f"{avg_time:.2f}m", "", "", f"{int(avg_isk):,}", f"{int(avg_iskph):,}")
            self.console.print(table)

        self.console.print("\n==============================", style="bold")
        self.console.print("ğŸ“ˆ ì „ì²´ ì–´ë¹„ì…œ í†µê³„ ğŸ“ˆ", style="bold")
        self.console.print("==============================", style="bold")
        if not self.df.empty:
            avg_isk = self.df['ì‹¤ìˆ˜ìµ'].mean()
            avg_time = self.df['ëŸ° ì†Œìš”(ë¶„)'].mean()
            avg_iskph = self.df['ISK/h'].mean()
            self.console.print(f"[ì „ì²´ í‰ê· ]   ğŸ•’ {avg_time:.2f}m   ğŸŸ¢ {int(avg_isk):,}   ğŸš€ {int(avg_iskph):,}")

            self.console.print("\n[í‹°ì–´/ë‚ ì”¨ë³„ í†µê³„]")
            table = Table()
            table.add_column("í‹°ì–´")
            table.add_column("ë‚ ì”¨")
            table.add_column("ëŸ°ìˆ˜", justify="right")
            table.add_column("ğŸŸ¢ í‰ê· ì‹¤ìˆ˜ìµ", justify="right")
            table.add_column("ğŸ•’ í‰ê· ëŸ°ì‹œê°„", justify="right")
            table.add_column("ğŸš€ í‰ê· ISK/h", justify="right")
            for (tier, weather), group in self.df.groupby(self.df['ì–´ë¹„ì…œ ì¢…ë¥˜'].str.split().str[0:2].apply(tuple)):
                if not group.empty:
                    table.add_row(
                        tier, weather, str(len(group)),
                        f"{int(group['ì‹¤ìˆ˜ìµ'].mean()):,}",
                        f"{group['ëŸ° ì†Œìš”(ë¶„)'].mean():.2f}",
                        f"{int(group['ISK/h'].mean()):,}"
                    )
            self.console.print(table)
        else:
            self.console.print("ë°ì´í„° ì—†ìŒ.")

if __name__ == "__main__":
    console = Console()
    eve_api = EVEApi()
    data_manager = AbyssalDataManager()
    analyzer = AbyssalPriceAnalyzer(eve_api, data_manager, console)
    analyzer.analyze()
